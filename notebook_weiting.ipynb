{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pds",
   "display_name": "pds"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Histopathologic Cancer Detection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 1. Installing libraries, downloading the dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(101)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "source": [
    "We are not allowed to share the dataset. Download the dataset from Kaggle by pip installing kaggle, and running `kaggle competitions download -c histopathologic-cancer-detection` in your terminal. Then, extract files from the histopathologic-cancer-detection.zip folder into a new folder called 'data'."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 96\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "SAMPLE_SIZE = 80000 # the number of images we use from each of the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "220025\n",
      "57458\n"
     ]
    }
   ],
   "source": [
    "# See image count in each folder\n",
    "print(len(os.listdir('data/train')))\n",
    "print(len(os.listdir('data/test')))"
   ]
  },
  {
   "source": [
    "# 2. Data Pre-processing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Now that the data has been properly loaded and set-up, we must now pre-process our data: in our case, we mainnly subset the data, augment the images, and split it into train and test.\n",
    "\n",
    "Note: The data takes hours to download in its full size, leaving a high possibility of crashing the kernel, not to mention the time required to train the model. Thus, we slightly modified someone else's preprocessing instructions throughout this entire stage to get a smaller subset of the data. This will make it faster and easier for us to run and train our model.\n",
    "\n",
    "https://www.kaggle.com/vbookshelf/cnn-how-to-use-160-000-images-without-crashing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Removing anomalous images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(220025, 2)\n"
     ]
    }
   ],
   "source": [
    "# Create a Dataframe containing all images\n",
    "data = pd.read_csv('data/train_labels.csv')\n",
    "\n",
    "# Removing this image because it caused a training error previously\n",
    "data[data['id'] != 'dd6dfed324f9fcb6f93f46f32fc800f2ec196be2']\n",
    "\n",
    "# Removing this image because it's black\n",
    "data[data['id'] != '9369c7278ec8bcc6c880d99194de09fc2bd4efbe']\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "source": [
    "## Augmenting image data\n",
    "\n",
    "Justification for augmentation\n",
    "\n",
    "This Kaggle challenge is a Machine Learning challenge. Machine learning however, requires plenty and diverse training data to accurately predict future data points without overfitting or underfitting. We have a lot of data points already, but also want to diversify them to prevent overfitting to the original data that may be too similar to each other already. We decided to augment the images in order to increase the diversity of images as inspired by this github repo below.\n",
    "\n",
    "https://github.com/aleju/imgaug"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for augmenting data\n",
    "from skimage.transform import rotate, AffineTransform\n",
    "import cv2\n",
    "from skimage.util import random_noise\n",
    "import random\n",
    "import os\n",
    "from skimage import io\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "ORIGINAL_SIZE = IMAGE_SIZE      # original size of the images - do not change\n",
    "\n",
    "# AUGMENTATION VARIABLES\n",
    "CROP_SIZE = 90          # final size after crop\n",
    "RANDOM_ROTATION = 3    # range (0-180), 180 allows all rotation variations, 0=no change\n",
    "RANDOM_SHIFT = 2        # center crop shift in x and y axes, 0=no change. This cannot be more than (ORIGINAL_SIZE - CROP_SIZE)//2 \n",
    "RANDOM_BRIGHTNESS = 7  # range (0-100), 0=no change\n",
    "RANDOM_CONTRAST = 5    # range (0-100), 0=no change\n",
    "RANDOM_90_DEG_TURN = 1  # 0 or 1= random turn to left or right\n",
    "\n",
    "def readCroppedImage(path, augmentations = True):\n",
    "    '''\n",
    "    This is a custom function to convert an input image, augment it through\n",
    "    random rotation, random x or y shift, random cropping, random flipping, \n",
    "    random changes in brightness and contrast, and returning it as an rgb tensor.\n",
    "    '''\n",
    "    # augmentations parameter is included for counting statistics from images, where we don't want augmentations\n",
    "    \n",
    "    # OpenCV reads the image in bgr format by default\n",
    "    bgr_img = cv2.imread(path)\n",
    "    # We flip it to rgb for visualization purposes\n",
    "    b,g,r = cv2.split(bgr_img)\n",
    "    rgb_img = cv2.merge([r,g,b])\n",
    "    \n",
    "    if(not augmentations):\n",
    "        return rgb_img / 255\n",
    "    \n",
    "    #random rotation\n",
    "    rotation = random.randint(-RANDOM_ROTATION,RANDOM_ROTATION)\n",
    "    if(RANDOM_90_DEG_TURN == 1):\n",
    "        rotation += random.randint(-1,1) * 90\n",
    "    M = cv2.getRotationMatrix2D((48,48),rotation,1)   # the center point is the rotation anchor\n",
    "    rgb_img = cv2.warpAffine(rgb_img,M,(96,96))\n",
    "    \n",
    "    #random x,y-shift\n",
    "    x = random.randint(-RANDOM_SHIFT, RANDOM_SHIFT)\n",
    "    y = random.randint(-RANDOM_SHIFT, RANDOM_SHIFT)\n",
    "    \n",
    "    # crop to center and normalize to 0-1 range\n",
    "    start_crop = (ORIGINAL_SIZE - CROP_SIZE) // 2\n",
    "    end_crop = start_crop + CROP_SIZE\n",
    "    rgb_img = rgb_img[(start_crop + x):(end_crop + x), (start_crop + y):(end_crop + y)] / 255\n",
    "    \n",
    "    # Random flip\n",
    "    flip_hor = bool(random.getrandbits(1))\n",
    "    flip_ver = bool(random.getrandbits(1))\n",
    "    if(flip_hor):\n",
    "        rgb_img = rgb_img[:, ::-1]\n",
    "    if(flip_ver):\n",
    "        rgb_img = rgb_img[::-1, :]\n",
    "        \n",
    "    # Random brightness\n",
    "    br = random.randint(-RANDOM_BRIGHTNESS, RANDOM_BRIGHTNESS) / 100.\n",
    "    rgb_img = rgb_img + br\n",
    "    \n",
    "    # Random contrast\n",
    "    cr = 1.0 + random.randint(-RANDOM_CONTRAST, RANDOM_CONTRAST) / 100.\n",
    "    rgb_img = rgb_img * cr\n",
    "    \n",
    "    # clip values to 0-1 range\n",
    "    rgb_img = np.clip(rgb_img, 0, 1.0)\n",
    "    \n",
    "    return img_as_ubyte(rgb_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(220026, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "#Augment test images randomly\n",
    "\n",
    "images_path=\"data/train\" #path to original images\n",
    "augmented_path=\"data/train\" # path to store augmented images\n",
    "images=[] # to store paths of images from folder\n",
    "\n",
    "for im in os.listdir(images_path):  # read image name from folder and append its path into \"images\" array     \n",
    "    images.append(os.path.join(images_path,im))\n",
    "\n",
    "images_to_generate=1 #you can change this value according to your requirement\n",
    "\n",
    "for i in range(images_to_generate):    \n",
    "    image=random.choice(images)\n",
    "    id = image[11:-4]\n",
    "    label = data[data['id'] == id].iloc[0]['label']\n",
    "    data = data.append({\"id\":'augmented_'+id,'label':label},ignore_index=True)\n",
    "    transformed_image= readCroppedImage(image)\n",
    "    new_image_path= \"train/augmented_%s.tif\" %(id)\n",
    "    cv2.imwrite(new_image_path, transformed_image) # save transformed image to path\n",
    "\n",
    "#Save new label file which has the augmented images\n",
    "data.to_csv('data/new_train_labels.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    130909\n",
       "1     89117\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "# Load the new csv that now includes the augmented images \n",
    "df_data = pd.read_csv('data/new_train_labels.csv')\n",
    "\n",
    "# Check the class distribution\n",
    "df_data['label'].value_counts()"
   ]
  },
  {
   "source": [
    "## Balance the target distribution\n",
    "\n",
    "As decided earlier with the variable SAMPLE_SIZE, we will subset our original data into 160000 images half labelled 0, the other labelled 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}